{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CVDL - Laboratory 6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1IfPVkblsYn"
      },
      "source": [
        "# Computer Vision and Deep Learning - Laboratory 6\n",
        " \n",
        "Congratulations, you made it till the last laboratory of the semester. This laboratory will be a bit different: it contains two parts and you can __choose__ at your own preference which of them you want to solve.  Of course, you can choose to solve both of them.\n",
        " \n",
        "The first part is related to _visualization_, while the second one is related to sequence models and vision transformers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73eaDA20lr9T"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1qTJrNimS9x"
      },
      "source": [
        "# Part 1. Visualizing what neural networks learn\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idxv04YymnlB"
      },
      "source": [
        "For this part you can either work with a neural network that you trained (perhaps for your project), or with a pre-trained model from tensorflow.\n",
        " \n",
        "For illustration purposes, I will load the Resnet network, pre-trained on Imagenet and, of course, an image of a cat.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "id": "jN_opFA5pYcK",
        "outputId": "da36551f-f0be-4b6f-ea2b-d1fb44b8380c"
      },
      "source": [
        "!wget -O cat.jpg https://img.freepik.com/free-photo/cat-white-background_155003-20502.jpg?size=626&ext=jpg\n",
        "\n",
        "img = cv2.imread('cat.jpg')\n",
        "img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "factor = 224.0/img.shape[1]\n",
        "img = cv2.resize(img, None, fx=factor, fy=factor)\n",
        "if img.shape[0] > img.shape[1]:\n",
        "  img = cv2.copyMakeBorder(img, top=0, bottom=0, left=(img.shape[0] - img.shape[1])//2, right=(img.shape[0] - img.shape[1])//2,\n",
        "                          borderType=cv2.BORDER_REPLICATE)\n",
        "else:\n",
        "    img = cv2.copyMakeBorder(img, top=(img.shape[1] - img.shape[0])//2, bottom=(img.shape[1] - img.shape[0])//2, left=0, right=0,\n",
        "                          borderType=cv2.BORDER_REPLICATE)\n",
        "# TODO fix size\n",
        "\n",
        "plt.imshow(img)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-01-01 19:07:36--  https://img.freepik.com/free-photo/cat-white-background_155003-20502.jpg?size=626\n",
            "Resolving img.freepik.com (img.freepik.com)... 184.85.237.135, 2600:1407:3c00:10a1::30ec, 2600:1407:3c00:1088::30ec\n",
            "Connecting to img.freepik.com (img.freepik.com)|184.85.237.135|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25662 (25K) [image/jpeg]\n",
            "Saving to: ‘cat.jpg’\n",
            "\n",
            "cat.jpg             100%[===================>]  25.06K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-01-01 19:07:36 (2.40 MB/s) - ‘cat.jpg’ saved [25662/25662]\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fc15d714610>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5p35id8ToLcJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ac4de4-6b4a-4bb9-ebb4-916399cadfdf"
      },
      "source": [
        "resnet50_model = ResNet50(weights='imagenet')\n",
        "resnet50_model.summary()\n",
        "#tf.keras.utils.plot_model(resnet50_model, show_shapes=True, show_dtype=True)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102973440/102967424 [==============================] - 1s 0us/step\n",
            "102981632/102967424 [==============================] - 1s 0us/step\n",
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " predictions (Dense)            (None, 1000)         2049000     ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 25,636,712\n",
            "Trainable params: 25,583,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Display the filters in the first and second convolutional layer\n",
        "\n",
        "Get the filters in the first and second convolutional layers and plot them. The filters in the first convolutional layer should be displayed as color images, while for the filters in the second layer you should display each channel individually as a grayscale image.\n",
        "\n",
        "Identify the names of these two layers and then use _layer.get_weights()_ to access the values of the filters."
      ],
      "metadata": {
        "id": "C4vW2mLKBTyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO your code here"
      ],
      "metadata": {
        "id": "miO5i9diCGsZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6AQsNvsnjxS"
      },
      "source": [
        "## Saliency map via image occlusions\n",
        " \n",
        "This visualization technique will output a heatmap which will highlight the regions that the model finds important when predicting a certain class.\n",
        " \n",
        "The implementation is straightforward: you just slide an occluding patch over the input image, and, for each position of the patch, feed the occluded image to the network and store the predictions (probas) of the model.\n",
        " \n",
        "Finally, display (as a heatmap) the probability of the correct class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70Kp9WYOoKr8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "outputId": "0d074004-a428-4141-e241-df5b85be7ff8"
      },
      "source": [
        "def compute_saliency_map(model, img, patch_size, stride):\n",
        "  \"\"\"\n",
        "  Succesivelly occlude the input imagw with a gray square patch of size patch_size.\n",
        "  When sliding the patch over the input image a step equal to stride is used.\n",
        "  \"\"\"\n",
        "  \n",
        "  # TODO your code here: pad the input image with patch_size/2\n",
        "\n",
        "  # TODO your code here: compute the size of the output\n",
        "  wo = None # the width of the output heatmap\n",
        "  ho = None # the height of the output heatmap\n",
        "  heatmap = np.zeros((ho, wo), dtype=np.float32)\n",
        "\n",
        "  for y in range(0, ho, stride):\n",
        "    # TODO your code here: create a 4d numpy array that will store the images from the current batch\n",
        "    for x in range(0, wo, stride):\n",
        "      # TODO your code here: apply a gray patch centered in (y, x)\n",
        "      # TODO your code here: add the occluded image in the current batch\n",
        "    # TODO your code here: feed the current image batch to the network\n",
        "    # TODO your code here: store the obtained class probas in the appropriate position in the heatmap\n",
        "  return heatmap\n",
        "\n",
        "# TODO your code here\n",
        "# call the function you just wrote on different input images and display the resulting heatmaps"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-37-af2780505b47>\"\u001b[0;36m, line \u001b[0;32m21\u001b[0m\n\u001b[0;31m    return heatmap\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saliency maps via image derivative\n",
        " \n",
        "This type of visualization tries to determine the pixels that contributed the most in the final classification.\n",
        "The main idea is to compute the derivative of the scores with respect to the input image. This derivative can be seen as a class saliency map for the input image (its magnitude tells us what pixels should be modified to change the class score the most).\n",
        " \n",
        "You can use a [GradientTape](https://www.tensorflow.org/api_docs/python/tf/GradientTape) to compute the gradients."
      ],
      "metadata": {
        "id": "4QVtwSjSeloe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_saliency_map(model, img):\n",
        "  \n",
        "  img = keras.preprocessing.image.img_to_array(img)\n",
        "  # expand the image, such that it has the shape (1, height, width, channels)\n",
        "  img = None\n",
        "  # preprocess image to get it into the right format for the model\n",
        "  img = None\n",
        "  \n",
        "  img = tf.Variable(img, dtype=float)\n",
        "\n",
        "  # use a gradient tape\n",
        "  with tf.GradientTape() as tape:\n",
        "      # feed the preprocessed image to the model\n",
        "      pred = model(img, training=False)\n",
        "      # TODO your code here: get the prediction with the highest probability\n",
        "      loss = None # the prediction with the highest score\n",
        "\n",
        "      # compute the gradient with respect to the image\n",
        "      grads = tape.gradient(loss, img)\n",
        "      # TODO your code here: take the absolute value of the gradient tf.math.abs\n",
        "      abs_grad = None \n",
        "      # TODO your code here: get the maximum across the channels of abs_grad\n",
        "      max_abs_grad = None \n",
        "\n",
        "      # TODO your code here: normalize to range between 0 and 1\n",
        "      grad_norm = None \n",
        "      return grad_norm\n",
        "\n",
        "\n",
        "\n",
        "img = None # TODO your image here\n",
        "saliency_map = compute_saliency_map(resnet50_model, img)\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(14,5))\n",
        "ax[0].imshow(img)\n",
        "ax[1].imshow(saliency_map,cmap=\"jet\")\n",
        "ax[2].imshow(saliency_map,cmap=\"gray\")\n"
      ],
      "metadata": {
        "id": "AnbU9z04hALW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## t-SNE visualization (optional)\n",
        "\n",
        "You can use the ImageNetes Apply t-SNE visualization on the last layer of the network that you chose.\n",
        "You can use the [T-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) module from sklean library.\n",
        "\n",
        "To create this visualization, you will need several images and their ground truth class. You could use some images from [imagenette](https://github.com/fastai/imagenette).\n",
        "\n",
        "Feed the images through your model and save the activation maps of the layer just before the classification layer (create a new model starting from the pre-trained architecture that you used and set that layer as the input). Then, use t-SNE visualization to view the classes (the colors of the points should be determined by the class of those images)."
      ],
      "metadata": {
        "id": "VwzWevVDhAz_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOLWatg-sb5g"
      },
      "source": [
        "# Deep-dream\n",
        "\n",
        "Follow this [tutorial](https://www.tensorflow.org/tutorials/generative/deepdream) related to DeepDream."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81aB7Dkisbbn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b90Q-R11mjqp"
      },
      "source": [
        "# Part 2. Sequence models and image transformers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text generation at character level\n",
        "\n",
        "\n",
        "Data processing \n",
        "\n",
        "- Load the training data [Poezii Eminescu.txt](https://ubbcluj.sharepoint.com/:t:/s/CVDL2021/EYeZJEN0aKNBs7xVblsELwgBaIpG7lF7VzDoMKs6fx7w0Q?e=QacxxQ) and determine the vocabulary for this problem \n",
        "\n",
        "- Encode the characters into a numerical representation: you should assign an id (number) for each character and, also, you should be able to determine retrieve the corresponding character of a given id \n",
        "\n",
        "- Split the training data into overlapping sequences of size _seq\\_size_ . X will be an array of  _seq\\_size_ from the text and the y (ground truth) will be the character that follows that sequence.\n",
        "\n",
        "- Transform the data to one hot encoding \n",
        "\n",
        "Model creation \n",
        "\n",
        "- Build a simple recurrent network: input layer, LSTM layer, dense layer  (softmax activation) \n",
        "\n",
        "Training \n",
        "\n",
        "- Compile and train the model (categorical_crossentropy loss) \n",
        "\n",
        "- Use ModelCheckpoint callback to save the model https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint  \n",
        "\n",
        "Text generation \n",
        "\n",
        "- Create a text sampling method: you could use a multinomial distribution to  sample the index of the next character from the softmax probas: \n",
        "\n",
        "https://numpy.org/doc/stable/reference/random/generated/numpy.random.multinomial.html  \n",
        "\n",
        "``\n",
        "next_character = argmax(np.random.multinomial(1, preds)) \n",
        "``\n",
        "\n",
        "Experiment with the temperature of softmax"
      ],
      "metadata": {
        "id": "zVSY62zGp3-p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_handler = open(\"Eminescu Poezii.txt\", \"r\")\n",
        "lines = file_handler.read().replace(\"\\n\", \" \")\n",
        "lowercase_lines = lines.lower()\n",
        "print(lowercase_lines[:30])"
      ],
      "metadata": {
        "id": "_MDYTj6np3cj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5361c51f-b1df-425a-abe7-d37f4097ed08"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \tla mormantul lui aron pumnul\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = set(lowercase_lines)\n",
        "print(len(vocabulary))\n",
        "print(vocabulary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0CjdKLd7Ken",
        "outputId": "87074f3a-ee6c-4efd-fe6e-c5530e851295"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n",
            "{'.', 'n', 'i', 's', '8', 'z', 'p', 'g', ':', '5', '\\t', '1', '-', 'u', 'c', '9', 'j', 'h', 'x', ',', 'k', '(', ' ', 'b', 'o', '!', 'e', 'm', 'v', 'd', 'y', ';', 'a', '?', '3', 'f', ']', '\"', '6', '2', 'w', 'l', ')', 'q', 't', 'r', '*', '['}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_to_index, index_to_vocabulary = {}, {}\n",
        "index = 0\n",
        "\n",
        "for character in vocabulary:\n",
        "  vocabulary_to_index[character] = index\n",
        "  index_to_vocabulary[index] = character\n",
        "  index += 1"
      ],
      "metadata": {
        "id": "TyGimQxH7gBa"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_length = 32\n",
        "stride = 5\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for character_index in range(0, len(lowercase_lines) - sequence_length, stride):\n",
        "  sequence = list(map(lambda x: vocabulary_to_index[x], lowercase_lines[character_index : character_index + sequence_length]))\n",
        "  truth = vocabulary_to_index[lowercase_lines[character_index + sequence_length]]\n",
        "  X.append(sequence)\n",
        "  y.append(truth)\n",
        "\n",
        "print(len(X), len(y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZRYpPHz7yrl",
        "outputId": "6599fbb7-ce5a-46c7-fc62-f1a0eaccd689"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "146137 146137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_one_hot_encoding = tf.keras.utils.to_categorical(y, num_classes=len(vocabulary), dtype='float32')\n",
        "x_one_hot_encoding = tf.keras.utils.to_categorical(X, num_classes=len(vocabulary), dtype='float32')"
      ],
      "metadata": {
        "id": "KFZ59XYj-n0p"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y[:10])\n",
        "print(y_one_hot_encoding[:10])\n",
        "print(x_one_hot_encoding.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGlkUo8H-xV_",
        "outputId": "c2445164-b34a-4b21-876d-ef5ca0e52886"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 14, 22, 24, 22, 24, 23, 2, 14, 6]\n",
            "[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
            "(146137, 32, 48)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_one_hot_encoding[0][-8])\n",
        "print(X[0][-8])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaPymIthAsCl",
        "outputId": "1ce01ee5-169b-4311-ef0d-49f189684a69"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=(sequence_length, len(vocabulary))))\n",
        "model.add(tf.keras.layers.LSTM(64))\n",
        "model.add(tf.keras.layers.Dense(len(vocabulary), activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_wZoKowBFEb",
        "outputId": "6fd708ce-c148-4a92-bc76-8d82d179f816"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 64)                28928     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 48)                3120      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32,048\n",
            "Trainable params: 32,048\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop()\n",
        "model.compile(optimizer, loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "model.fit(x_one_hot_encoding, y_one_hot_encoding, epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8sDmv8mCImO",
        "outputId": "b3412f50-8704-4d2c-a709-f9abb99b0af6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "4567/4567 [==============================] - 71s 14ms/step - loss: 2.3873 - accuracy: 0.2814\n",
            "Epoch 2/50\n",
            "4567/4567 [==============================] - 72s 16ms/step - loss: 2.1338 - accuracy: 0.3461\n",
            "Epoch 3/50\n",
            "4567/4567 [==============================] - 65s 14ms/step - loss: 2.0376 - accuracy: 0.3742\n",
            "Epoch 4/50\n",
            "4567/4567 [==============================] - 65s 14ms/step - loss: 1.9736 - accuracy: 0.3957\n",
            "Epoch 5/50\n",
            "4567/4567 [==============================] - 62s 13ms/step - loss: 1.9258 - accuracy: 0.4111\n",
            "Epoch 6/50\n",
            "4567/4567 [==============================] - 61s 13ms/step - loss: 1.8901 - accuracy: 0.4206\n",
            "Epoch 7/50\n",
            "4567/4567 [==============================] - 64s 14ms/step - loss: 1.8616 - accuracy: 0.4294\n",
            "Epoch 8/50\n",
            "4567/4567 [==============================] - 60s 13ms/step - loss: 1.8389 - accuracy: 0.4353\n",
            "Epoch 9/50\n",
            "4567/4567 [==============================] - 63s 14ms/step - loss: 1.8201 - accuracy: 0.4420\n",
            "Epoch 10/50\n",
            "4567/4567 [==============================] - 67s 15ms/step - loss: 1.8040 - accuracy: 0.4466\n",
            "Epoch 11/50\n",
            "4567/4567 [==============================] - 67s 15ms/step - loss: 1.7899 - accuracy: 0.4502\n",
            "Epoch 12/50\n",
            "4567/4567 [==============================] - 66s 14ms/step - loss: 1.7774 - accuracy: 0.4536\n",
            "Epoch 13/50\n",
            "4567/4567 [==============================] - 65s 14ms/step - loss: 1.7668 - accuracy: 0.4570\n",
            "Epoch 14/50\n",
            "4567/4567 [==============================] - 62s 13ms/step - loss: 1.7567 - accuracy: 0.4603\n",
            "Epoch 15/50\n",
            "4567/4567 [==============================] - 60s 13ms/step - loss: 1.7476 - accuracy: 0.4622\n",
            "Epoch 16/50\n",
            "4567/4567 [==============================] - 64s 14ms/step - loss: 1.7395 - accuracy: 0.4649\n",
            "Epoch 17/50\n",
            "4567/4567 [==============================] - 64s 14ms/step - loss: 1.7319 - accuracy: 0.4668\n",
            "Epoch 18/50\n",
            "4567/4567 [==============================] - 62s 14ms/step - loss: 1.7250 - accuracy: 0.4691\n",
            "Epoch 19/50\n",
            "4567/4567 [==============================] - 60s 13ms/step - loss: 1.7187 - accuracy: 0.4703\n",
            "Epoch 20/50\n",
            "4567/4567 [==============================] - 60s 13ms/step - loss: 1.7126 - accuracy: 0.4729\n",
            "Epoch 21/50\n",
            "4567/4567 [==============================] - 64s 14ms/step - loss: 1.7073 - accuracy: 0.4735\n",
            "Epoch 22/50\n",
            "4567/4567 [==============================] - 60s 13ms/step - loss: 1.7023 - accuracy: 0.4754\n",
            "Epoch 23/50\n",
            "4567/4567 [==============================] - 59s 13ms/step - loss: 1.6973 - accuracy: 0.4769\n",
            "Epoch 24/50\n",
            "4567/4567 [==============================] - 59s 13ms/step - loss: 1.6930 - accuracy: 0.4772\n",
            "Epoch 25/50\n",
            "3473/4567 [=====================>........] - ETA: 14s - loss: 1.6841 - accuracy: 0.4808"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, sequence, length):\n",
        "  generated_text = sequence\n",
        "  sequence = [vocabulary_to_index[character] for character in sequence]\n",
        "  \n",
        "  for character_index in range(length):\n",
        "    sequence_to_predict = tf.keras.utils.to_categorical(sequence, num_classes=len(vocabulary), dtype='float32')\n",
        "    sequence_to_predict = np.reshape(sequence_to_predict, (1, *sequence_to_predict.shape))\n",
        "    character = model(sequence_to_predict)[0]\n",
        "    next_character = np.argmax(np.random.multinomial(1, character))\n",
        "    sequence = sequence[1:]\n",
        "    sequence.append(next_character)\n",
        "    next_character = index_to_vocabulary[next_character]\n",
        "    generated_text += next_character\n",
        "  return generated_text\n"
      ],
      "metadata": {
        "id": "dRy6vxixC2qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXzIFbeZtIzS"
      },
      "source": [
        "Follow this [tutorial](https://keras.io/examples/vision/image_classification_with_vision_transformer/) about image transformers.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate(model, lowercase_lines[:31], 20)"
      ],
      "metadata": {
        "id": "rioGPF1HC1xO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}